# TricubeNet: 2D Kernel-Based Object Representation for Weakly-Occluded Oriented Object Detection

> Beomyoung Kim

|Model|mAP|Conference|Recommond|
|--|--|--|--|
|TricubeNet|75.26|WACV2022|:white_check_mark:|

提出了一种新的面向对象检测方法，称为TricubeNet，它使用视觉线索（即热图）而不是面向框偏移回归来定位面向对象。

将每个对象表示为二维三立方核，并使用简单的图像处理算法提取边界框

方法能够（1）从视觉线索中获得排列良好的方框，（2）解决角度不连续性问题，以及（3）由于我们的无锚建模，可以节省计算复杂性。

为了进一步提高性能，提出了一些有效的技术，用于尺寸不变损失、减少错误检测、提取旋转不变特征和热图细化。

---

首先，对于密集排列的定向对象，相邻水平边界框之间的并集交集（IOU）往往较大，其中一些框将通过非最大抑制（NMS）过滤掉。

第二，由于水平边界框可以包含许多冗余区域，因此它不适用于需要更紧密和更精确的框的真实应用，例如航空图像和场景文本图像。

大多数定向对象检测器[7、26、40]采用更快的R-CNN[32]或视网膜网[21]作为其基线模型，并另外推断对象的角度。他们采用锚增广策略，以5个偏移（x，y，w，h，θ）或8个偏移（x1，y1，x2，y2，x3，y3，x4，y4）的形式回归定向盒偏移。他们以最先进的表演登上了王位，但仍存在一些限制。（1） 如图1所示，回归框偏移可能难以获得密集排列的定向对象的排列良好的框；（2） 回归角度偏移会导致角度不连续问题；边界上的角度不连续性导致训练过程中的损耗波动；（3） 由于锚扩展和定向盒的大量IoU计算，它们需要巨大的计算复杂度。例如，当它们定义具有三个尺度、五个纵横比和六个角度的锚定框，并采用具有800×800输入分辨率的FPN[20]架构时，它们总共需要约4M个锚定框（每个像素位置3×5×6=90个锚定盒）。有些人可能会认为[28，48]等无锚方法可以降低计算复杂度，但由于角度回归，它们也会遇到角度不连续问题。

使用视觉提示（即热图）而不是框偏移回归。如图1所示，我们将每个对象表示为二维三立方核，其形状直观地描述了对象的宽度、高度和角度，然后使用简单的图像处理算法提取边界框。我们的方法能够（1）从排列对象的视觉线索中获得排列良好的定向框，如图1所示，（2）通过去除角度回归来解决角度不连续性问题，（3）由于我们的无锚建模而节省计算复杂性，以及（4）是一个简单的单级无锚检测器。

此外，为了获得竞争结果，我们应该处理面向对象检测的一些挑战性因素：对象的各种形状和大小、密集排列的对象、大量对象、错误检测和背景的复杂性。为了应对这些挑战性因素，我们提出了一些技术。第一种是SizeWight掩码（SWM）。逐像素均方误差（MSE）损失导致尺寸不平衡问题，即，小对象往往会受到小损失，从而削弱小对象的检测。为了制作尺寸不变的损失函数，我们提出了SWM。其次，为了平衡前景和背景像素之间的损失，同时减少误报检测，我们引入了一种误报示例挖掘（FPEM）技术。第三，我们提出了一个多角度卷积（MAC）模块来提取面向对象的旋转变量特征。最后，我们设计了一个重复的细化阶段来细化输出热图，并将此技术称为热图级联细化。

TricubeNet通过一个简单的无锚单阶段过程，可以非常有效地检测面向对象
