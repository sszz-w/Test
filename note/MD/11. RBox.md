# Few Could Be Better Than All: Feature Sampling and Grouping for Scene Text Detection

> Jingqun Tang, CVPR2022

|Model|mAP|Conference|Recommond|
|--|--|--|--|
|RBox|79.59|CVPR2022|:white_check_mark:|

基于Transformer的方法可以消除NMS等后处理并丰富深度表示，然而，由于尺度和纵横比的极端变化，这些方法不能很好地处理场景文本

论文提出了一种简单而有效的基于transformer的场景文本检测架构

与以前以整体方式学习场景文本的鲁棒深度表示的方法不同，他们的方法基于一些代表性特征进行场景文本检测，避免了背景的干扰并降低了计算成本

- 首先在所有尺度上选择一些与前景文本高度相关的代表性特征

- 采用transformer对采样特征的关系进行建模，有效地将它们划分为合理的组；由于每个特征组对应一个文本实例，因此无需任何后处理操作即可轻松获得其边界框

- 使用基本特征金字塔网络进行特征提取

---

存在的问题：不同尺度、复杂光照、透视失真、多方向、复杂形状、还依赖复杂的处理来恒诚或细化预测结果：锚点生成、非极大值抑制NMS、二值化、轮廓提取

将Transformer引入到视觉任务中，来提取全局范围特征并为长距离建模图像中的依赖

基于Detr的方法，使用transformer从以前的对象检测框架中移除了复杂的手工设计过程(NMS、锚生成)

但是在处理小对象和高计算复杂度的时候会有问题

基于DETR的场景文本检测器无法在ICDAR2015数据集和ICDAR2017-MLT数据集上实现令人满意的检测精度，因为这两个数据集中的文本实例具有更大的尺度和纵横比方差

transformer通常不足以在小尺度下捕获特征图上的小文本，而使用多尺度特征图的基于DETR的方法的时间成本是不可预测的

高分辨率特征图中的意外背景噪声将显著增加计算成本并干扰transformer建模

不需要使用所有像素的关系进行特征学习，因为前景文本实例只占据场景图像中的几个小而窄的区域

- 首先采样并收集与场景文本高度相关的特征

- 然后，采用transformer来建模采样特征之间的关系，以便对它们进行适当分组

1. 它可以显著消除冗余背景信息，这有利于提高检测过程的有效性和效率
2. 使用transformer对采样特征进行分组，可以获得更准确的分组结果和边界框，而无需任何后处理操作
3. 由于特征采样和分组是以端到端的方式实现的，这两个阶段可以共同提高最终检测性能
